{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f11c05d",
   "metadata": {},
   "source": [
    "## Customer Call Analytics using NLP & Semantic Embeddings\n",
    "\n",
    "This project applies end-to-end Natural Language Processing (NLP) techniques to customer service call data, including speech-to-text, sentiment analysis, named entity recognition, semantic similarity, and unsupervised clustering to extract actionable business insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f8e36",
   "metadata": {},
   "source": [
    "# !pip install SpeechRecognition\n",
    "# !pip install pydub\n",
    "# !pip install spacy\n",
    "# !python3 -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0143e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sapan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "c:\\Python312\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1bb49f",
   "metadata": {},
   "source": [
    "### Audio Download & Speech-to-Text (ASR)\n",
    "- Convert a customer call audio recording into text using automatic speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b672b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file downloaded as sample_customer_call.wav\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.voiptroubleshooter.com/open_speech/american/OSR_us_000_0010_8k.wav\"\n",
    "output_file = \"sample_customer_call.wav\"\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(output_file, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"Audio file downloaded as sample_customer_call.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b79318",
   "metadata": {},
   "source": [
    "Note: Audio is downloaded for demonstration purposes. Main analysis uses provided call transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d76c4",
   "metadata": {},
   "source": [
    "### Sentiment Analysis (VADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049bfe60",
   "metadata": {},
   "source": [
    "**Predict sentiment of each customer call using VADER, a lexicon-based sentiment analyzer optimized for conversational text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97134b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"customer_call.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8b6c2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>how's it going Arthur I just placed an order w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yeah hello I'm just wondering if I can speak t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hey I receive my order but it's the wrong size...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hi David I just placed an order online and I w...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hey I bought something from your website the o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text sentiment_label\n",
       "0      0  how's it going Arthur I just placed an order w...        negative\n",
       "1      1  yeah hello I'm just wondering if I can speak t...         neutral\n",
       "2      2  hey I receive my order but it's the wrong size...        negative\n",
       "3      3  hi David I just placed an order online and I w...         neutral\n",
       "4      4  hey I bought something from your website the o...        negative"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0f835",
   "metadata": {},
   "source": [
    "**Initialize VADER sentiment model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a2756a",
   "metadata": {},
   "source": [
    "VADER is lexicon + rule-based (not deep learning).\n",
    "It outputs 4 scores:\n",
    "- pos, neu, neg (0–1)\n",
    "- compound (-1 to +1) overall sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70a46169",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e0fde48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment by evaluating compound score generated by Vader SentimentIntensityAnalyzer\n",
    "def find_sentiment(text):\n",
    "    scores = sid.polarity_scores(text)\n",
    "    compound_score = scores['compound']\n",
    "\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad4859",
   "metadata": {},
   "source": [
    "**Apply predictions to each row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0583875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_predicted'] = df.apply(lambda row: find_sentiment(row[\"text\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = len(df.loc[\n",
    "    (df['sentiment_predicted'] == df['sentiment_label']) &\n",
    "    (df['sentiment_label'] == 'positive')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e938c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d84c6281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I've just bought a product new guys and I want...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>I purchase something from your online store ye...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I got my order yesterday and the order number ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>hi I recently ordered a new phone and I'm just...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>hi I placed an order a couple days ago and I w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment_label  \\\n",
       "14  I've just bought a product new guys and I want...         neutral   \n",
       "58  I purchase something from your online store ye...        negative   \n",
       "93  I got my order yesterday and the order number ...         neutral   \n",
       "98  hi I recently ordered a new phone and I'm just...         neutral   \n",
       "47  hi I placed an order a couple days ago and I w...        negative   \n",
       "\n",
       "   sentiment_predicted  \n",
       "14            positive  \n",
       "58            positive  \n",
       "93            positive  \n",
       "98            positive  \n",
       "47            positive  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = df[df[\"sentiment_label\"] != df[\"sentiment_predicted\"]]\n",
    "errors[[\"text\", \"sentiment_label\", \"sentiment_predicted\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c27c8e",
   "metadata": {},
   "source": [
    "Misclassifications often occur with polite complaints or implicit dissatisfaction, highlighting limitations of rule-based sentiment models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e7040aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.56      0.64        43\n",
      "     neutral       0.70      0.49      0.58        57\n",
      "    positive       0.07      1.00      0.12         2\n",
      "\n",
      "    accuracy                           0.53       102\n",
      "   macro avg       0.51      0.68      0.45       102\n",
      "weighted avg       0.71      0.53      0.59       102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df[\"sentiment_label\"], df[\"sentiment_predicted\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2374cf",
   "metadata": {},
   "source": [
    "**Negative**\n",
    "\n",
    "- When the model predicts negative, it’s usually right (75%)\n",
    "- But it misses ~44% of actual negative complaints\n",
    "\n",
    "**Why**\n",
    "\n",
    "- Customers often complain politely\n",
    "- VADER struggles with indirect dissatisfaction (“I was just wondering why…”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba97916",
   "metadata": {},
   "source": [
    "**Neutral**\n",
    "\n",
    "- Neutral is frequently confused with negative or positive\n",
    "- Model finds only half of true neutral calls\n",
    "\n",
    "**Why**\n",
    "\n",
    "- Customer service language is ambiguous\n",
    "- Many neutral calls contain emotional words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec10d8a2",
   "metadata": {},
   "source": [
    "What’s happening\n",
    "\n",
    "- There are only 2 positive examples\n",
    "- Model predicts “positive” too easily\n",
    "- Almost all positive predictions are wrong\n",
    "\n",
    "**This is class imbalance,**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9bf1b5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c653cb",
   "metadata": {},
   "source": [
    "## TASK 3 — Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c802df1",
   "metadata": {},
   "source": [
    "**Extract named entities (e.g., people, dates) from customer conversations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a99518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd42ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff4e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['named_entities'] = df['text'].apply(extract_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd669001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_predicted</th>\n",
       "      <th>named_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>how's it going Arthur I just placed an order w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>[Arthur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yeah hello I'm just wondering if I can speak t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yesterday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hey I receive my order but it's the wrong size...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hi David I just placed an order online and I w...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[David]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hey I bought something from your website the o...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text sentiment_label  \\\n",
       "0      0  how's it going Arthur I just placed an order w...        negative   \n",
       "1      1  yeah hello I'm just wondering if I can speak t...         neutral   \n",
       "2      2  hey I receive my order but it's the wrong size...        negative   \n",
       "3      3  hi David I just placed an order online and I w...         neutral   \n",
       "4      4  hey I bought something from your website the o...        negative   \n",
       "\n",
       "  sentiment_predicted named_entities  \n",
       "0            negative       [Arthur]  \n",
       "1            positive    [yesterday]  \n",
       "2            negative             []  \n",
       "3             neutral        [David]  \n",
       "4             neutral             []  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4d3f5",
   "metadata": {},
   "source": [
    "**Find most frequent entity overall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a08f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = [ent for entities in df['named_entities'] for ent in entities]\n",
    "entities_df = pd.DataFrame(all_entities, columns=['entity'])\n",
    "entities_counts = entities_df['entity'].value_counts().reset_index()\n",
    "entities_counts.columns = ['entity', 'count']\n",
    "most_freq_ent = entities_counts[\"entity\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cffccaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yesterday'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_ent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4893f",
   "metadata": {},
   "source": [
    "### Named Entity Analysis\n",
    "\n",
    "Named Entity Recognition (NER) was applied using spaCy’s `en_core_web_sm`\n",
    "model to extract entities from customer call transcripts.\n",
    "\n",
    "The most frequently occurring entity was **\"yesterday\"**, classified as a\n",
    "temporal (`DATE`) entity. This reflects the conversational nature of customer\n",
    "support interactions, where callers frequently reference recent events such as\n",
    "order placement or delivery timing.\n",
    "\n",
    "This insight highlights the importance of temporal context in customer\n",
    "complaints and suggests that time-based features could be valuable for\n",
    "downstream analysis or escalation workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b245d5d1",
   "metadata": {},
   "source": [
    "## Find most similar complaint (Semantic Similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039845c3",
   "metadata": {},
   "source": [
    "**Process each call into a spaCy Doc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f5d6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['text'].apply(lambda text: nlp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78894076",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = \"wrong package delivery\"\n",
    "processed_query = nlp(input_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a938285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sapan\\AppData\\Local\\Temp\\ipykernel_37520\\2586716001.py:2: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  lambda text: processed_query.similarity(text)\n"
     ]
    }
   ],
   "source": [
    "df['similarity'] = df['processed_text'].apply(\n",
    "    lambda text: processed_query.similarity(text)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b0b2d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar text:  wrong package delivered\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(by='similarity', ascending=False)\n",
    "most_similar_text = df[\"text\"].iloc[0]\n",
    "print(\"Most similar text: \", most_similar_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10a23ad",
   "metadata": {},
   "source": [
    "## Semantic Similarity (Modern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c637c4",
   "metadata": {},
   "source": [
    "Improve similarity search using transformer-based sentence embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "669e6070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 369.06it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a05ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(corpus, query):\n",
    "    corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    return scores.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0028c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Similarity\n",
    "query = \"wrong package delivery\"\n",
    "df[\"similarity\"] = compute_similarity(df[\"text\"].tolist(), query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab8e9c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64fb00cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_predicted</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>wrong package delivered</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>[]</td>\n",
       "      <td>(wrong, package, delivered)</td>\n",
       "      <td>0.938691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>the shipment I received is wrong</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>[]</td>\n",
       "      <td>(the, shipment, I, received, is, wrong)</td>\n",
       "      <td>0.726414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>the shipment I received is wrong</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>[]</td>\n",
       "      <td>(the, shipment, I, received, is, wrong)</td>\n",
       "      <td>0.726414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>a couple of days ago I got a message saying th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[a couple of days ago]</td>\n",
       "      <td>(a, couple, of, days, ago, I, got, a, message,...</td>\n",
       "      <td>0.653485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>hello someone from your team delivered my pack...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>[today]</td>\n",
       "      <td>(hello, someone, from, your, team, delivered, ...</td>\n",
       "      <td>0.636427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               text sentiment_label  \\\n",
       "81     81                            wrong package delivered        negative   \n",
       "41     41                   the shipment I received is wrong        negative   \n",
       "44     44                   the shipment I received is wrong        negative   \n",
       "33     33  a couple of days ago I got a message saying th...        negative   \n",
       "39     39  hello someone from your team delivered my pack...        negative   \n",
       "\n",
       "   sentiment_predicted          named_entities  \\\n",
       "81            negative                      []   \n",
       "41            negative                      []   \n",
       "44            negative                      []   \n",
       "33             neutral  [a couple of days ago]   \n",
       "39            negative                 [today]   \n",
       "\n",
       "                                       processed_text  similarity  \n",
       "81                        (wrong, package, delivered)    0.938691  \n",
       "41            (the, shipment, I, received, is, wrong)    0.726414  \n",
       "44            (the, shipment, I, received, is, wrong)    0.726414  \n",
       "33  (a, couple, of, days, ago, I, got, a, message,...    0.653485  \n",
       "39  (hello, someone, from, your, team, delivered, ...    0.636427  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bb4c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar complaint to query:\n",
      "\n",
      "wrong package delivered\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMost similar complaint to query:\\n\")\n",
    "print(df.iloc[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd5d209",
   "metadata": {},
   "source": [
    "## Optional Clustering (Unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c02b74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def cluster_texts(embeddings, k=4):\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    return model.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a4edd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedder.encode(df[\"text\"].tolist())\n",
    "df[\"cluster\"] = cluster_texts(embeddings, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0714253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample clustered complaints:\n",
      "\n",
      "\n",
      "Cluster 0:\n",
      "['I just placed an order I was wondering how long shipping time would be expected to be'\n",
      " 'hi I just recently placed an order with your company I was just wondering if you know the status of my shipment']\n",
      "\n",
      "Cluster 1:\n",
      "[\"I'm calling out to talk about a package I got yesterday it so I got it but I need to do I need some help with setting it up\"\n",
      " 'hey mate how you doing just calling in regards to the phone I just purchased from you guys faulty not working and there was damaged on the way here']\n",
      "\n",
      "Cluster 2:\n",
      "['wrong package delivered' 'the shipment I received is wrong']\n",
      "\n",
      "Cluster 3:\n",
      "[\"just received the product from you guys and it didn't meet my expectations can I please get a refund\"\n",
      " \"hey I receive my order but it's the wrong size can I get a refund please\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample clustered complaints:\\n\")\n",
    "for c in range(4):\n",
    "    print(f\"\\nCluster {c}:\")\n",
    "    print(df[df[\"cluster\"] == c][\"text\"].head(2).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b09fc83",
   "metadata": {},
   "source": [
    "### Unsupervised Complaint Clustering\n",
    "\n",
    "Customer complaints were embedded using a transformer-based sentence\n",
    "embedding model and grouped using KMeans clustering.\n",
    "\n",
    "The model identified four coherent complaint categories without the use of\n",
    "labels:\n",
    "\n",
    "- **Cluster 0 – Order Status & Shipping**: inquiries about delivery time and\n",
    "  shipment status\n",
    "- **Cluster 1 – Product Issues & Setup**: damaged products and setup assistance\n",
    "- **Cluster 2 – Wrong Delivery**: incorrect or mismatched shipments\n",
    "- **Cluster 3 – Refunds & Returns**: dissatisfaction, wrong size, or refund\n",
    "  requests\n",
    "\n",
    "The resulting clusters align closely with real-world customer support\n",
    "workflows, demonstrating the effectiveness of semantic embeddings for\n",
    "automated issue categorization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
